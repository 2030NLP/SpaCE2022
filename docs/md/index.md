
<br/>

# 第二届中文空间语义理解评测<small>（SpaCE2022）</small>

空间范畴是人类认知中重要的基础范畴。理解文本中的空间信息不仅需要掌握字词含义，还需要具有常识或背景知识，要调动语言范畴之外的空间想象等认知能力。

空间语义理解在NLP领域也长期受到关注，是NLP评测的重要内容之一，但以往相关评测任务主要关注语言中正确的空间语义信息的分析。人类在能够识别常规、正确的空间信息的同时，还能够识别异常、错误的空间信息。如对于“在四面签一个名字”，人类能够意识到其中存在异常，因为“一个名字”通常不会签在“四面”；又如“跳进山洞外”，“跳进”搭配的必须是表达一个空间内部方位的成分，如“山洞中、山洞里”，无法搭配“山洞外”。显然，空间方位表达的异常存在不同的类型，如词语搭配问题、上下文语义冲突问题、违反常识或背景信息的问题等。

基于以上认识，我们于2021年依托 <a target="_blank" href="http://cips-cl.org/static/CCL2021/cclEval/taskEvaluation/index.html">CCL2021</a> 成功举办了首届中文空间语义理解评测任务（SpaCE，Spatial Cognition Evaluation）。

今年，我们依托 <a href="http://cips-cl.org/static/CCL2022/index.html" target="_blank">CCL2022</a> ，继续推出<span style="color:var(--notice-red)">**第二届中文空间语义理解评测（SpaCE2022）**</span>。

- 主办单位：北京大学
- 组织者：詹卫东，穗志方
- 工作人员：孙春晖，李楠，邢丹，王诚文，岳朋雪，王希豪，邱晓枫，祝方韦 等
- 联系方式：sc_eval@163.com

<a target="_blank" href="https://2030nlp.github.io/SpaCE2022/register"><span style="color:var(--notice-red)">👉 **点我立即报名** 👈</span></a>

> - [任务简介](#intro)
> - [数据概况](#data-overview)
>   - [子任务1：中文空间语义正误判断](sub-task-1)
>   - [子任务2：中文空间语义异常归因](sub-task-2)
>   - [子任务3：中文空间实体识别与空间方位关系标注任务](sub-task-3)
> - [评测指标](#eval)
> - [比赛日程](#schedule)
> - [报名方式](#register)
> - [奖项设置](#award)
> - [附录](#appendix)



<br/><span id="intro"></span>

### 1.  任务内容

#### 1.1  任务简介

空间范畴是人类认知中重要的基础范畴。理解文本中的空间信息不仅需要掌握字词含义，还需要具有常识或背景知识，要调动语言范畴之外的空间想象等认知能力。

空间语义理解在NLP领域也长期受到关注，是NLP评测的重要内容之一，但以往相关评测任务主要关注语言中正确的空间语义信息的分析。人类在能够识别常规、正确的空间信息的同时，还能够识别异常、错误的空间信息。如对于“在四面签一个名字”，人类能够意识到其中存在异常，因为“一个名字”通常不会签在“四面”；又如“跳进山洞外”，“跳进”搭配的必须是表达一个空间内部方位的成分，如“山洞中、山洞里”，无法搭配“山洞外”。显然，空间方位表达的异常存在不同的类型，如词语搭配问题、上下文语义冲突问题、违反常识或背景信息的问题等。

基于以上认识，我们于2021年首次提出中文空间语义理解评测任务（SpaCE，Spatial Cognition Evaluation）。在SpaCE2021的基础上，现组织第二届中文空间语义理解评测（SpaCE2022），分为如下3个子任务：

**子任务1，中文空间语义正误判断**：判断给定的中文文本中是否存在空间语义异常。

**子任务2，中文空间语义异常归因**：识别给定中文文本中空间语义异常的片段及其类型。

**子任务3，中文空间实体识别与空间方位关系标注任务**：基于给定的空间关系标注规范，对给定中文文本进行空间实体的识别与空间方位关系标注。

#### 1.2  与 SpaCE2021 的比较

SpaCE2022 与 SpaCE2021 相比，有如下变化：

- ① 使用新的语料资源，制作了<span style="color:var(--notice-red)">**全新**</span>的数据集，扩大了数据规模。SpaCE2022 在语料筛选上更加严格，增加了更多更适用于空间语义理解的语料（来自体育、地理、交通等领域），减少了不适合的语料（如武侠小说、散文等）。同时，在制作数据集时引入了更严格的质量控制机制，提高了数据质量。
- ② 调整了子任务2（归因任务）的形式。SpaCE2021 中以判断题的形式来评估机器对空间异常的归因能力，其评估意义不够充分、直接；SpaCE2022 要求参赛系统直接给出存在异常的文本片段及归因类型，能够更直观地体现其归因能力。同时，也调整了归因任务中的归因类型，从先前的 4 种类型凝练为 3 种，更具归纳性。
- ③ 取消了联合任务，增加了标注任务。SpaCE2021 中的子任务3是前两个任务的联合，因此与前两个任务考察的能力有所重复；SpaCE2022 则引入标注型任务，相较于判断和归因，对参赛系统的空间语义理解能力提出了更高要求，与前两个子任务形成层层递进，从而对参赛系统实现更全方位的考察。

两次评测的比较如下表所示：

|            | SpaCE2021                                                    | SpaCE2022                                                    |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 任务设置 | 子任务1：中文空间语义正误判断<br />子任务2：中文空间语义异常归因合理性判断<br />子任务3：中文空间语义判断与归因联合任务 | 子任务1：中文空间语义正误判断<br />子任务2：中文空间语义异常归因<br />子任务3：中文空间实体识别与空间方位关系标注任务 |
| 归因类型   | 搭配问题、语义问题、语境问题、常识问题                       | 搭配不当、语义冲突、不符合常识或背景信息                     |
| 语料来源   | 主要来源于CCL语料库，涵盖小说、散文、词典等文体              | 来源更加丰富，涉及文学、体育、新闻、地理、交通等多种领域     |
| 数据规模   | 7k+ 段原始语料，约 86 万字符                                 | 30k+ 段原始语料，约 285 万字符                               |

> 注：第一届中文空间语义理解评测（SpaCE2021）的相关资源可访问以下链接获取：
>
> - Github 仓库： <a target="_blank" href="https://github.com/2030NLP/SpaCE2021">https://github.com/2030NLP/SpaCE2021</a>
> - 评测网站： <a target="_blank" href="http://ccl.pku.edu.cn:8084/SpaCE2021/">http://ccl.pku.edu.cn:8084/SpaCE2021/</a>
> - CCL2021 评测研讨会资讯： <a target="_blank" href="http://cips-cl.org/static/CCL2021/cclEval/taskEvaluation/index.html">http://cips-cl.org/static/CCL2021/cclEval/taskEvaluation/index.html</a>
<!-- > - Github 仓库： https://github.com/2030NLP/SpaCE2021 -->
<!-- > - 评测网站： http://ccl.pku.edu.cn:8084/SpaCE2021/ -->
<!-- > - 研讨会资讯： http://cips-cl.org/static/CCL2021/cclEval/taskEvaluation/index.html -->



<br/><span id="data-overview"></span>

### 2.  评测数据

#### 2.1  任务要求与数据样例

各子任务的要求说明及样例如下。

<span id="sub-task-1"></span>

##### 2.1.1  子任务1：中文空间语义正误判断

子任务1（中文空间语义正误判断）的数据包含3个部分：① qid：试题编号；② context：待判断的文本材料内容；③ judge：对材料空间语义正误的判断结果（正常为 1 ，异常为 0 ）。该任务要求参赛系统对于输入的 context 返回 judge 。

样例如下：

> 输入：
>
> ```json
> { "qid": "1-train-841",
>   "context": "斯石英可以在实验室里制造，但它们在自然界下存在吗？回答是肯定的。然而它们只出现在沙子被强烈挤压的地方。"  }
> ```
>
> 输出：
>
> ```json
> { "qid": "1-train-841",
>   "judge": 0  }
> ```
>
> 解释： 根据上下文，应该说“在自然界中存在吗”，而不是“在自然界下存在”，因此存在异常，输出 0

更多细节可参考： [SpaCE2022 数据标注文档](https://2030nlp.github.io/Sp22AnnoOL/menu) 。



<br/><span id="sub-task-2"></span>

##### 2.1.2  子任务2：中文空间语义异常归因

子任务2（中文空间语义异常归因）的数据包含以下内容：

- ① qid：试题编号；
- ② context：存在空间语义异常的文本；
- ③ reasons：由若干文本片段（fragments）和一个类型标记（type）构成。
  - 每个文本片段（fragment）包含 3 个字段，分别是角色（role）、文本内容（text）和字序数组（idxes）。其中 role 与归因的类型（type）有关。

每个 reason 可能的 type 有以下 3 种：

- `A` **搭配不当**，对应 2 个文本片段，其角色 role 分别为 `text1` 和 `text2` （顺序以在 context 中的出现顺序为准）。此归因的含义是：text1 与 text2 对应的文本片段通常不会搭配在一起。如 `“text1 空气”与“text2 旁”搭配不当`、`“text1 地面”与“text2 边”搭配不当` 等。
- `B` **语义冲突**，对应 6 个文本片段，涵盖两组“空间实体-空间方位-事件”（S-P-E）的三元组，其 role 分别为 `S1 P1 E1 S2 P2 E2` 。此归因的含义是：两组 S-P-E 三元组彼此冲突，不可能同时成立。如 `“[S1 手臂, P1 垂直于地面, E1 举]”与“[S2 手臂, E2 平行于地面, E2 举]”语义冲突`、`“[S1 钥匙, P1 在桌下, E1 放]”与“[S2 钥匙, P2 桌上, E2 捡起]”`等。
- `C` **不符合常识或背景信息**，对应 3 个文本片段，即一组 S-P-E 三元组，其 role 分别为 `S P E` 。此归因的含义是：这组 S-P-E 三元组在常识中或在上下文所描述的情境中是不合理的。如 `“[S 双手, P 在裤子口袋外, E 插]”不符合常识或背景信息`、`“[S 项圈, P 脖子旁, E 戴]”不符合常识或背景信息` 等。

该任务要求参赛系统对于输入的 context 返回 reasons 数组。评价时取提交答案与参考答案中匹配程度最高的单个 reason 进行计分。

数据样例如下：

> 输入：
>
> ```json
> { "qid": "2-train-221",
>   "context": "我国著名学者童第周在1978年成功地进行了黑斑蛙的克隆试验。他将黑斑蛙的红细胞的核移入事先除去了核的黑斑蛙卵前，这种换核卵最后长成能在水中自由游泳的蝌蚪。"  }
> ```
>
> 输出：
>
> ```json
> { "qid": "2-train-221",
>   "reasons": [
>     { "fragments": [
>        { "role": "text1", "text": "移入", "idxes": [41,42]},
>        { "role": "text2", "text": "卵前", "idxes": [53,54]}],
>       "type": "A" },
>     { "fragments": [
>        { "role": "S", "text": "黑斑蛙的红细胞的核", "idxes": [32,33,34,35,36,37,38,39,40]},
>        { "role": "P", "text": "除去了核的黑斑蛙卵前", "idxes": [45,46,47,48,49,50,51,52,53,54]},
>        { "role": "E", "text": "移入", "idxes": [41,42]}],
>       "type": "C" },
>     { "fragments": [
>        { "role": "S", "text": "红细胞的核", "idxes": [36,37,38,39,40]},
>        { "role": "P", "text": "黑斑蛙卵前", "idxes": [50,51,52,53,54]},
>        { "role": "E", "text": "移入", "idxes": [41,42]}],
>       "type": "C" },
>     { "fragments": [
>        { "role": "S", "text": "核", "idxes": [40]},
>        { "role": "P", "text": "卵前", "idxes": [53,54]},
>        { "role": "E", "text": "移入", "idxes": [41,42]}],
>       "type": "C" }  ]  }
> ```

特别说明：

1. 文本片段 fragment 的字序号数组 idxes 描述了 text 中每个字符在 context 中的序号。序号从 0 开始计。请特别注意： <span class="fw-bold" style="color:var(--notice-red)">idxes 不一定连续</span> 。如描述空间方位的 P P1 P2 角色的文本可能将 context 中分离的“从北京”和“到上海”拼接在一起。
2. 在单个 reason 中，<span class="fw-bold" style="color:var(--notice-red)">每个文本内容或者具体字符不一定只出现一次</span>。尤其是对于 B 类（语义冲突）的归因，S1 与 S2、P1 与 P2 以及 E1 与 E2 都有可能具有相同的 text 和/或 idxes 。
3. 对于 B 类和 C 类的 reason ，<span style="color:var(--notice-red)">文中不一定出现某些特定的 role 内容，此时该 role 可以缺省</span>。
4. 参考答案会提供多种可能的答案，<span class="fw-bold" style="color:var(--notice-red)">参赛者可提交 A, B, C 三类答案各 1 个</span>，评分时会取答案中取得最高分的 1 个答案进行计分。<span style="color:var(--notice-red)">如果提交的 reasons 数组中包含多条同一类型的归因，那么评分时仅会取此类第 1 条归因进行计算</span>。

更详细的数据说明可参考： [SpaCE2022 数据标注文档](https://2030nlp.github.io/Sp22AnnoOL/menu) 。



<br/><span id="sub-task-3"></span>

##### 2.1.3  子任务3：中文空间实体识别与空间方位关系标注任务

子任务3（中文空间实体识别与空间方位关系标注任务）的数据包含以下内容：

- ① qid：试题编号；
- ② context：存在空间语义异常的文本；
- ③ outputs：若干描述空间实体及其空间方位信息构成的18元组。
- ④ corefs：列出了文中不同形但同指的文本片段。（供评分使用，由主办方留存，无需参赛者提交）
- ⑤ non_corefs：列出了文中同形但不同指的文本片段。（供评分使用，由主办方留存，无需参赛者提交）

<mark>更详细的数据说明将于子任务3正式发布时公布</mark>，另可参考： [SpaCE2022 数据标注文档](https://2030nlp.github.io/Sp22AnnoOL/menu) 。



<br/>

#### 2.2  数据规模与分布

各子任务各子集数据规模如下表所示：

|任务|训练集|验证集|测试集|总计|
|----|-----|---|----|----|
|子任务1| 10993 | 1602 | 3152 | 15747 |
|子任务2| 4966 | 700 | 1402 | 7068 |
|子任务3| 1541 | 210 | 400 | 2151 |

语料共计 285.2 万字符，每段语料字符数均值为 114.24，标准差为 49.57。语料涉及多种不同类型和来源，各类语料比例为：中小学课本语料（20%）、体育训练语料（6%）、新闻报道语料（37%）、文学作品语料（25%）、地理百科语料（2%）、交通判决书语料（9%），以及其他语料（1%）。



<br/><span id="eval"></span>

### 3.  评价标准

#### 3.1  子任务1的评价标准

子任务1使用准确率（ *`Acc`* ，Accuracy）作为评价指标，公式如下：

```python
Acc = 命中正确答案的题数 / 题目总数
```

#### 3.2  子任务2的评价标准

子任务2按照以下步骤计算得分，作为评价指标：

1. 取出提交结果的 reasons 中 A/B/C 每类的第 1 个 reason 作为待检查的答案。
2. 对于每个待检查的 reason （称为“待检项”），与参考答案中的 reasons （称为“参考项”）进行逐个比较，分别计算以下 3 个指标：
   - ① 异常类型分类准确性：即待检项与参考项的 type 是否相同。
   - ② 异常文本识别准确性：即待检项与参考项整个 reason 中全部 text 的 *`F1`* 值，公式为 `F1 = 2 * P * R / (P + R)` ，其中 *`P`* 、 *`R`* 分别代表精确率（Precision）和召回率（Recall）。此时不考虑 type 和 role 。
   - ③ 异常元素识别准确性：即待检项与参考项各个特定 role 的 text 的 *`F1`* 值（公式同上）的均值。
3. 按三种指标分别找到得分最高的待检项，以此项得分计为该题在这一指标上的最终得分。
4. 最后，对所有题目计算 指标①的准确率 以及 指标②③的平均值 作为参赛者在各指标上的最终得分。评测将以 指标③ 作为最终排名依据，而 指标①② 则供研究参考，

#### 3.3  子任务3的评价标准

<mark>（将于子任务3正式发布时一同公布）</mark>

#### 3.4  最终排名

在所有参赛队伍的评测结果产生之后，计算每个任务下各个队伍的标准分数（Z-score），对三个任务的标准分数取平均，作为最终排名的依据。标准分数计算公式如下，其中 *`X̄`* 为平均数， *`s`* 为标准差：

```python
Z = (X - X̄) / s
```



<br/><span id="schedule"></span>

### 4.  评测赛程

| 时间 | 事项 |
| :--: | :--: |
| 6月1日~8月20日 | 开放报名 |
| 8月8日 | 发布子任务1和子任务2的训练集及无答案验证集，开放结果提交 |
| 8月12日前 | 发布子任务3的训练集及无答案验证集 |
| 8月18日 | 发布验证集答案 |
| 9月18日 | 发布无答案的测试集，开始提交测试集结果 |
| 9月28日 | 测试集结果提交截止 |
| 10月8日 | 提交最终版本的模型及技术报告 |
| 10月14日~10月16日 | 评测研讨会，公布结果 |

<!-- （以上时间均为暂定，请关注 [CCL 2022](http://cips-cl.org/static/CCL2022/index.html) 官方网站。） -->
（以上时间为暂定，请以实际通知为准。）




<br/><span id="register"></span>

### 5.  报名方式

请仔细阅读《<a target="_blank" href="https://github.com/2030NLP/SpaCE2022/blob/main/Agreement.md">第二届中文空间语义理解评测 SpaCE2022 参赛协议</a>》和《<a target="_blank" href="https://github.com/2030NLP/SpaCE2022/blob/main/data/LICENSE.md">第二届中文空间语义理解评测 SpaCE2022 数据集使用许可</a>》，

然后点击进入 <a target="_blank" href="https://2030nlp.github.io/SpaCE2022/register">报名链接</a> 进行报名。



<br/><span id="award"></span>

### 6.  奖项设置

**评测奖金由华为公司赞助**，奖池共计 50000 元人民币。

一等奖 0-2名 ，奖金合计 20000 元<!-- （如 1*20000, 2*10000） -->

二等奖 0-2名 ，奖金合计 15000 元<!-- （如 1*15000, 2*7500） -->

三等奖 0-4名 ，奖金合计 15000 元<!-- （如 1*15000, 2*7500, 3*5000, 4*3500） -->

由中国中文信息学会为本次评测获奖队伍提供荣誉证书。



<br/><span id="appendix"></span>

### 附录

- <a target="_blank" href="https://github.com/2030NLP/SpaCE2022/blob/main/Agreement.md">第二届中文空间语义理解评测 SpaCE2022 参赛协议</a>
- <a target="_blank" href="https://github.com/2030NLP/SpaCE2022/blob/main/data/LICENSE.md">第二届中文空间语义理解评测 SpaCE2022 数据集使用许可</a>
<!-- - [第二届中文空间语义理解评测 SpaCE2022 参赛协议](https://github.com/2030NLP/SpaCE2022/blob/main/Agreement.md) -->
<!-- - [第二届中文空间语义理解评测 SpaCE2022 数据集使用许可](https://github.com/2030NLP/SpaCE2022/blob/main/data/LICENSE.md) -->

